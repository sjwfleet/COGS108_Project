{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project (change this to your project's title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [X] YES - make available\n",
    "* [  ] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your overview here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Samuel\n",
    "- Matthew\n",
    "- Caitlin\n",
    "- Darren\n",
    "- Nick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do large online communities ( of retail traders) have influence over the stock market?\n",
    "\n",
    "*Sentiment analysis of positivity on the Reddit subreddit r/WallStreetBets and how this correlates to the performance of the S&P 500 from January 31, 2012 to the present.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='background'></a>\n",
    "\n",
    "## Background & Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reddit was considered a good community for us to hone in on for our topic not just because of its size, but also because it has a dedicated system for us to more easily scrape semi-structured data from the site. We are able to do this with the Python Reddit API Wrapper (PRAW). For the past few days the subreddit r/WallStreetBets has been the center of the trading world with its short squeeze of the Gamestock (GME), AMC Theaters (AMC), and BlackBerry (BB) stocks and more. Their history of trading in a reckless manner goes back much further than just the past few weeks. In this project we look at the trading done in the months leading up to and during the Covid-19 pandemic and how it correlates to several stocks including the S&P 500, TSLA, GME, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keith Gill, also know as the Roaring Kitty on Reddit, Tik Tok, and Youtube, invested $53,000 into GameStop (3). Recently he and his followers invested into GameStop against hedge funds and went against Wall Street norms. He and his fellow investors drove up the price of GameStop, which is still climbing to this day (4). Because Gill's base was mainly on Reddit, we were curious if there was any correlation with the positivity of the subreddit he frequented and the S&P 500. We did some research to see if scraping data from reddit was possible, and according to (2), it would be quite simple to create our own dataset using Reddit's API. We also looked into Kaggle, to see what our ideal dataset would look like (1). Using these resources, we feel confident in our ability to webscrape our own Reddit dataset. We also looked into downloading a dataset from websites that have the history and time periods of stocks. Yahoo Finance provides an easy way to download a dataset with the variables we need in .csv format (4).\n",
    "\n",
    "\n",
    "References (include links):\n",
    "- 1) https://www.kaggle.com/shergreen/wallstreetbets-subreddit-submissions\n",
    "- 2) https://towardsdatascience.com/scraping-reddit-data-1c0af3040768\n",
    "- 3) https://www.nytimes.com/2021/01/29/technology/roaring-kitty-reddit-gamestop-markets.html\n",
    "- 4) https://finance.yahoo.com/quote/GME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that there is a correlation between the positivity on the subreddit and the performance of the S&P 500 due to global and local events. Global events, especially the COVID-19 pandemic, may hold an influence over the subreddit and the market.\n",
    "- We also hypothesize that there will be a positive linear relationship between the performance of the S&P 500 and positivity on the popular subredditr r/WallStreetBets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Dataset\n",
    "\n",
    "- Dataset Name: Stock Market S&P 500 History \n",
    "- Link to the dataset: https://finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC\n",
    "- Number of observations: 2,273\n",
    "\n",
    "This dataset contains the date, open, high, low, close, adjusted close, and volume of the S&P 500 from January 31, 2012 to February 10, 2021. We got this dataset from Yahoo Finance, which allows us to easily download the history of the S&P 500 into a CSV file. We chose this time period as the subreddit r/wallstreetbets was created on January 31, 2012. In our data cleaning code, we will only keep the date and closing columns.\n",
    "\n",
    "\n",
    "\n",
    "#### Reddit Dataset\n",
    "\n",
    "- Dataset Name: Wallstreetbets Subs Full\n",
    "- Link to the dataset: https://drive.google.com/file/d/1l3NuVbJtf9mdMdvLsKRnj0rcfYYp7o28/view?usp=sharing\n",
    "- Number of observations: 1,317,200\n",
    "\n",
    "Our team found a dataset on Kaggle that gave us the submissions on r/wallstreetbets in a dataset that went up to August 2020. To ensure we covered the entire period within the scope of our question we elected to acquire our own data using wrappers for the Reddit API. We have included our webscraping code below. We webscraped the Reddit API from January 31, 2012 (when the subreddit was created) to the present. This dataset contains submissions to the subreddit. Other columns include features in Reddit (awards, removals, etc.) as well as links to posts and authors. We will be cleaning this up to better organize the data by date and post content.\n",
    "\n",
    "*Our stock dataset is included in the GitHub folder.*\n",
    "\n",
    "*Our reddit dataset is provided in a Google Drive link as the file is 1.7 gb.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "#!pip install pmaw\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from pmaw import PushshiftAPI\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Market S&P 500 History \n",
    "\n",
    "Our question is associated with how the positivity of the subreddit r/wallstreetbets correlates to the performance of the S&P 500 from January 31, 2012 to the present. This dataset before cleaning is already very clean. We just need to remove certain columns in order to get what we need to answer our research question. Therefore, we will just need the date and the closing price of the S&P 500. We do not need the adjusted close due to that we are working with the S&P 500 and don't need to work with out of hours like we would with an individual stock or the the opening price since it will just be the previous day's closing price. Since we are only considering the performance of the S&P 500, we do not need the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/31/2012</td>\n",
       "      <td>1312.410034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/2012</td>\n",
       "      <td>1324.089966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/2/2012</td>\n",
       "      <td>1325.540039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/3/2012</td>\n",
       "      <td>1344.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/6/2012</td>\n",
       "      <td>1344.329956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>2/4/2021</td>\n",
       "      <td>3871.739990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>2/5/2021</td>\n",
       "      <td>3886.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>2/8/2021</td>\n",
       "      <td>3915.590088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>2/9/2021</td>\n",
       "      <td>3911.229980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>2/10/2021</td>\n",
       "      <td>3909.879883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2273 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Close\n",
       "0     1/31/2012  1312.410034\n",
       "1      2/1/2012  1324.089966\n",
       "2      2/2/2012  1325.540039\n",
       "3      2/3/2012  1344.900024\n",
       "4      2/6/2012  1344.329956\n",
       "...         ...          ...\n",
       "2268   2/4/2021  3871.739990\n",
       "2269   2/5/2021  3886.830078\n",
       "2270   2/8/2021  3915.590088\n",
       "2271   2/9/2021  3911.229980\n",
       "2272  2/10/2021  3909.879883\n",
       "\n",
       "[2273 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_csv(\"Stock_Market_S&P_500_History.csv\")\n",
    "cleaned_stocks = stocks[['Date', 'Close']]\n",
    "cleaned_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to webscrape Reddit API\n",
    "\n",
    "This was used outside of our notebook in order to webscrape the Reddit API for the subreddit r/wallstreetbets from January 31, 2012 to February 12, 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pmaw import PushshiftAPI\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "outname = 'wallstreetbets_subs_full.csv'\n",
    "\n",
    "outdir = './data'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "fullname = os.path.join(outdir, outname)\n",
    "\n",
    "api = PushshiftAPI()\n",
    "submissions = api.search_submissions(subreddit=\"wallstreetbets\", after=1327968000, before=1613160000)\n",
    "\n",
    "sub_df = pd.DataFrame(submissions)\n",
    "sub_df.to_csv(fullname, header=True, index=False, columns=list(sub_df.axes[1]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallstreetbets Subs Full\n",
    "\n",
    "We webscraped the subreddit r/wallstreetbets for a consistent time period. The Kaggle dataset we found stopped at August 2020. We wanted a time period that would span from when the subreddit was created (January 31, 2012) to the present. Our dataset, when first webscraped, has many unnecessary columns. Considering how our research question only asks about the positivity of the subreddit, columns such as 'subreddit', and 'event_is_live' are unneeded. We will be focusing on the following columns: selftext, author_fullname, title, url, total_awards_received, upvote_ratio, category, and created_utc. Some columns are associated with Reddit features that do not pertain to our research question. We also further cleaned our dataset by renaming some columns for better understanding. Such columns include changing the name from author_fullname to Author ID, and title to Post Title. We avoided removing too many columns right now in the case we find that some of the other columns become relevant later on in our data exploration process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>full_link</th>\n",
       "      <th>gilded</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>content_categories</th>\n",
       "      <th>hidden</th>\n",
       "      <th>quarantine</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>event_end</th>\n",
       "      <th>event_is_live</th>\n",
       "      <th>event_start</th>\n",
       "      <th>collections</th>\n",
       "      <th>top_awarded_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svb688</td>\n",
       "      <td>1.302398e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_52yit</td>\n",
       "      <td>1356455353</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15fc9y</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dasweb</td>\n",
       "      <td>1.279150e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_46mmt</td>\n",
       "      <td>1356378910</td>\n",
       "      <td>finance.yahoo.com</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15dyf8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GroundhogExpert</td>\n",
       "      <td>1.292783e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_4mwkh</td>\n",
       "      <td>1356330888</td>\n",
       "      <td>seekingalpha.com</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15d3ig</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StockTrader8</td>\n",
       "      <td>1.350310e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_9b4e5</td>\n",
       "      <td>1356222842</td>\n",
       "      <td>keeneonthemarket.com</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15ay8i</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StockTrader8</td>\n",
       "      <td>1.350310e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_9b4e5</td>\n",
       "      <td>1356043510</td>\n",
       "      <td>keeneonthemarket.com</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156y2e</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GroundhogExpert</td>\n",
       "      <td>1.292783e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_4mwkh</td>\n",
       "      <td>1356041481</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156vsr</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mkipper</td>\n",
       "      <td>1.263318e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_3tlyc</td>\n",
       "      <td>1356016701</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1564oi</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kdonn</td>\n",
       "      <td>1.323061e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_6djdk</td>\n",
       "      <td>1355964582</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1551zx</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GroundhogExpert</td>\n",
       "      <td>1.292783e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_4mwkh</td>\n",
       "      <td>1355955444</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154s0h</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dasweb</td>\n",
       "      <td>1.279150e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_46mmt</td>\n",
       "      <td>1355850121</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15241a</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            author  author_created_utc author_flair_css_class  \\\n",
       "0           svb688        1.302398e+09                    NaN   \n",
       "1           Dasweb        1.279150e+09                    NaN   \n",
       "2  GroundhogExpert        1.292783e+09                    NaN   \n",
       "3     StockTrader8        1.350310e+09                    NaN   \n",
       "4     StockTrader8        1.350310e+09                    NaN   \n",
       "5  GroundhogExpert        1.292783e+09                    NaN   \n",
       "6          mkipper        1.263318e+09                    NaN   \n",
       "7            kdonn        1.323061e+09                    NaN   \n",
       "8  GroundhogExpert        1.292783e+09                    NaN   \n",
       "9           Dasweb        1.279150e+09                    NaN   \n",
       "\n",
       "  author_flair_text author_fullname  created_utc                domain  \\\n",
       "0               NaN        t2_52yit   1356455353   self.wallstreetbets   \n",
       "1               NaN        t2_46mmt   1356378910     finance.yahoo.com   \n",
       "2               NaN        t2_4mwkh   1356330888      seekingalpha.com   \n",
       "3               NaN        t2_9b4e5   1356222842  keeneonthemarket.com   \n",
       "4               NaN        t2_9b4e5   1356043510  keeneonthemarket.com   \n",
       "5               NaN        t2_4mwkh   1356041481   self.wallstreetbets   \n",
       "6               NaN        t2_3tlyc   1356016701   self.wallstreetbets   \n",
       "7               NaN        t2_6djdk   1355964582   self.wallstreetbets   \n",
       "8               NaN        t2_4mwkh   1355955444   self.wallstreetbets   \n",
       "9               NaN        t2_46mmt   1355850121   self.wallstreetbets   \n",
       "\n",
       "                                           full_link  gilded      id  ...  \\\n",
       "0  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15fc9y  ...   \n",
       "1  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15dyf8  ...   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15d3ig  ...   \n",
       "3  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15ay8i  ...   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...     0.0  156y2e  ...   \n",
       "5  https://www.reddit.com/r/wallstreetbets/commen...     0.0  156vsr  ...   \n",
       "6  https://www.reddit.com/r/wallstreetbets/commen...     0.0  1564oi  ...   \n",
       "7  https://www.reddit.com/r/wallstreetbets/commen...     0.0  1551zx  ...   \n",
       "8  https://www.reddit.com/r/wallstreetbets/commen...     0.0  154s0h  ...   \n",
       "9  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15241a  ...   \n",
       "\n",
       "   content_categories hidden quarantine  removal_reason  \\\n",
       "0                 NaN    NaN        NaN             NaN   \n",
       "1                 NaN    NaN        NaN             NaN   \n",
       "2                 NaN    NaN        NaN             NaN   \n",
       "3                 NaN    NaN        NaN             NaN   \n",
       "4                 NaN    NaN        NaN             NaN   \n",
       "5                 NaN    NaN        NaN             NaN   \n",
       "6                 NaN    NaN        NaN             NaN   \n",
       "7                 NaN    NaN        NaN             NaN   \n",
       "8                 NaN    NaN        NaN             NaN   \n",
       "9                 NaN    NaN        NaN             NaN   \n",
       "\n",
       "   subreddit_name_prefixed event_end  event_is_live  event_start collections  \\\n",
       "0                      NaN       NaN            NaN          NaN         NaN   \n",
       "1                      NaN       NaN            NaN          NaN         NaN   \n",
       "2                      NaN       NaN            NaN          NaN         NaN   \n",
       "3                      NaN       NaN            NaN          NaN         NaN   \n",
       "4                      NaN       NaN            NaN          NaN         NaN   \n",
       "5                      NaN       NaN            NaN          NaN         NaN   \n",
       "6                      NaN       NaN            NaN          NaN         NaN   \n",
       "7                      NaN       NaN            NaN          NaN         NaN   \n",
       "8                      NaN       NaN            NaN          NaN         NaN   \n",
       "9                      NaN       NaN            NaN          NaN         NaN   \n",
       "\n",
       "  top_awarded_type  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "5              NaN  \n",
       "6              NaN  \n",
       "7              NaN  \n",
       "8              NaN  \n",
       "9              NaN  \n",
       "\n",
       "[10 rows x 114 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The below code was run on a local machine due to size constraints of our CSV\n",
    "\n",
    "reddit = pd.read_csv(\"../wallstreetbets_subs_full.csv\", low_memory = False)\n",
    "reddit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author', 'author_created_utc', 'author_flair_css_class', 'author_flair_text', 'author_fullname', 'created_utc', 'domain', 'full_link', 'gilded', 'id', 'is_self', 'media_embed', 'mod_reports', 'num_comments', 'over_18', 'permalink', 'retrieved_on', 'score', 'secure_media_embed', 'selftext', 'stickied', 'subreddit', 'subreddit_id', 'thumbnail', 'title', 'url', 'user_reports', 'edited', 'media', 'secure_media', 'banned_by', 'locked', 'post_hint', 'preview', 'link_flair_css_class', 'link_flair_text', 'approved_at_utc', 'banned_at_utc', 'brand_safe', 'can_mod_post', 'contest_mode', 'is_video', 'spoiler', 'suggested_sort', 'thumbnail_height', 'thumbnail_width', 'author_flair_richtext', 'author_flair_type', 'is_crosspostable', 'is_original_content', 'is_reddit_media_domain', 'link_flair_richtext', 'link_flair_text_color', 'link_flair_type', 'media_only', 'no_follow', 'num_crossposts', 'parent_whitelist_status', 'pinned', 'pwls', 'rte_mode', 'send_replies', 'subreddit_subscribers', 'subreddit_type', 'whitelist_status', 'wls', 'link_flair_background_color', 'link_flair_template_id', 'author_cakeday', 'author_flair_background_color', 'author_flair_text_color', 'crosspost_parent', 'crosspost_parent_list', 'all_awardings', 'allow_live_comments', 'author_patreon_flair', 'author_premium', 'awarders', 'gildings', 'is_meta', 'is_robot_indexable', 'total_awards_received', 'removed_by_category', 'author_flair_template_id', 'updated_utc', 'media_metadata', 'treatment_tags', 'upvote_ratio', 'url_overridden_by_dest', 'is_gallery', 'distinguished', 'steward_reports', 'discussion_type', 'view_count', 'previous_visits', 'removed_by', 'gallery_data', 'og_description', 'og_title', 'author_id', 'poll_data', 'archived', 'can_gild', 'category', 'content_categories', 'hidden', 'quarantine', 'removal_reason', 'subreddit_name_prefixed', 'event_end', 'event_is_live', 'event_start', 'collections', 'top_awarded_type']\n"
     ]
    }
   ],
   "source": [
    "# Print columns to get a better sense of what data is where, and what we know we don't need\n",
    "\n",
    "collist = list(reddit)\n",
    "print(collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Checking all posts are from one subreddit\n",
    "\n",
    "allinsubreddit = sum(reddit['subreddit'] != 'wallstreetbets')\n",
    "print(allinsubreddit)\n",
    "\n",
    "# Yes they are, dropping the redundant column\n",
    "reddit.drop('subreddit', axis=1, inplace=True)\n",
    "\n",
    "# Also dropping 3 columns with information unrelated to our scope\n",
    "#reddit.drop(['event_end','event_is_live','event_start'], axis=1)\n",
    "\n",
    "reddit.drop('spoiler', axis=1, inplace=True)\n",
    "reddit.drop('author_patreon_flair', axis=1, inplace=True)\n",
    "reddit.drop('author_premium', axis=1, inplace=True)\n",
    "reddit.drop(reddit.iloc[:, 103:107], inplace=True, axis=1) \n",
    "reddit.drop(reddit.iloc[:, 109:114], inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>full_link</th>\n",
       "      <th>gilded</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>poll_data</th>\n",
       "      <th>archived</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>category</th>\n",
       "      <th>content_categories</th>\n",
       "      <th>hidden</th>\n",
       "      <th>quarantine</th>\n",
       "      <th>event_start</th>\n",
       "      <th>collections</th>\n",
       "      <th>top_awarded_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svb688</td>\n",
       "      <td>1.302398e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_52yit</td>\n",
       "      <td>1356455353</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15fc9y</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dasweb</td>\n",
       "      <td>1.279150e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_46mmt</td>\n",
       "      <td>1356378910</td>\n",
       "      <td>finance.yahoo.com</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15dyf8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GroundhogExpert</td>\n",
       "      <td>1.292783e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_4mwkh</td>\n",
       "      <td>1356330888</td>\n",
       "      <td>seekingalpha.com</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15d3ig</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StockTrader8</td>\n",
       "      <td>1.350310e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_9b4e5</td>\n",
       "      <td>1356222842</td>\n",
       "      <td>keeneonthemarket.com</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15ay8i</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StockTrader8</td>\n",
       "      <td>1.350310e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_9b4e5</td>\n",
       "      <td>1356043510</td>\n",
       "      <td>keeneonthemarket.com</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156y2e</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GroundhogExpert</td>\n",
       "      <td>1.292783e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_4mwkh</td>\n",
       "      <td>1356041481</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156vsr</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mkipper</td>\n",
       "      <td>1.263318e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_3tlyc</td>\n",
       "      <td>1356016701</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1564oi</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kdonn</td>\n",
       "      <td>1.323061e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_6djdk</td>\n",
       "      <td>1355964582</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1551zx</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GroundhogExpert</td>\n",
       "      <td>1.292783e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_4mwkh</td>\n",
       "      <td>1355955444</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154s0h</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dasweb</td>\n",
       "      <td>1.279150e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_46mmt</td>\n",
       "      <td>1355850121</td>\n",
       "      <td>self.wallstreetbets</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15241a</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author  author_created_utc author_flair_css_class  \\\n",
       "0           svb688        1.302398e+09                    NaN   \n",
       "1           Dasweb        1.279150e+09                    NaN   \n",
       "2  GroundhogExpert        1.292783e+09                    NaN   \n",
       "3     StockTrader8        1.350310e+09                    NaN   \n",
       "4     StockTrader8        1.350310e+09                    NaN   \n",
       "5  GroundhogExpert        1.292783e+09                    NaN   \n",
       "6          mkipper        1.263318e+09                    NaN   \n",
       "7            kdonn        1.323061e+09                    NaN   \n",
       "8  GroundhogExpert        1.292783e+09                    NaN   \n",
       "9           Dasweb        1.279150e+09                    NaN   \n",
       "\n",
       "  author_flair_text Author ID  created_utc                domain  \\\n",
       "0               NaN  t2_52yit   1356455353   self.wallstreetbets   \n",
       "1               NaN  t2_46mmt   1356378910     finance.yahoo.com   \n",
       "2               NaN  t2_4mwkh   1356330888      seekingalpha.com   \n",
       "3               NaN  t2_9b4e5   1356222842  keeneonthemarket.com   \n",
       "4               NaN  t2_9b4e5   1356043510  keeneonthemarket.com   \n",
       "5               NaN  t2_4mwkh   1356041481   self.wallstreetbets   \n",
       "6               NaN  t2_3tlyc   1356016701   self.wallstreetbets   \n",
       "7               NaN  t2_6djdk   1355964582   self.wallstreetbets   \n",
       "8               NaN  t2_4mwkh   1355955444   self.wallstreetbets   \n",
       "9               NaN  t2_46mmt   1355850121   self.wallstreetbets   \n",
       "\n",
       "                                           full_link  gilded      id  ...  \\\n",
       "0  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15fc9y  ...   \n",
       "1  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15dyf8  ...   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15d3ig  ...   \n",
       "3  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15ay8i  ...   \n",
       "4  https://www.reddit.com/r/wallstreetbets/commen...     0.0  156y2e  ...   \n",
       "5  https://www.reddit.com/r/wallstreetbets/commen...     0.0  156vsr  ...   \n",
       "6  https://www.reddit.com/r/wallstreetbets/commen...     0.0  1564oi  ...   \n",
       "7  https://www.reddit.com/r/wallstreetbets/commen...     0.0  1551zx  ...   \n",
       "8  https://www.reddit.com/r/wallstreetbets/commen...     0.0  154s0h  ...   \n",
       "9  https://www.reddit.com/r/wallstreetbets/commen...     0.0  15241a  ...   \n",
       "\n",
       "   poll_data archived can_gild  category  content_categories hidden  \\\n",
       "0        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "1        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "2        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "3        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "4        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "5        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "6        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "7        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "8        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "9        NaN      NaN      NaN       NaN                 NaN    NaN   \n",
       "\n",
       "   quarantine  event_start collections top_awarded_type  \n",
       "0         NaN          NaN         NaN              NaN  \n",
       "1         NaN          NaN         NaN              NaN  \n",
       "2         NaN          NaN         NaN              NaN  \n",
       "3         NaN          NaN         NaN              NaN  \n",
       "4         NaN          NaN         NaN              NaN  \n",
       "5         NaN          NaN         NaN              NaN  \n",
       "6         NaN          NaN         NaN              NaN  \n",
       "7         NaN          NaN         NaN              NaN  \n",
       "8         NaN          NaN         NaN              NaN  \n",
       "9         NaN          NaN         NaN              NaN  \n",
       "\n",
       "[10 rows x 106 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming a few columns for clarity\n",
    "\n",
    "reddit.rename(columns={'author':'Author', 'author_fullname':'Author ID', 'title':'Post Title', 'upvote_ratio':'Upvote Ratio'}, inplace=True)\n",
    "reddit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barebones filtered dataset for us to do initial work. Important that we could keep it to a manageable size for github\n",
    "filtered = reddit.filter(['Author ID','Post Title', 'Upvote Ratio', 'created_utc', 'category', 'total_awards_received', 'score', 'selftext'], axis=1)\n",
    "filtered.to_csv(\"../filteredout.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallstreetbets Subs Filtered 1\n",
    "\n",
    "These two sections are separated since the above section imports the massive 1.7gb dataset that only 2 of our team could actually use on their local computer without breaking. Even when run on systems that could handle it the above cells took a long time. So we only run the above cells once to get the filteredout.csv and import it here to continue working with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = pd.read_csv(\"../filteredout.csv\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384480"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many of these are NaN, so we will just leverage Score instead\n",
    "filtered['Upvote Ratio'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1317200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approx all NaN, so dropping this column\n",
    "filtered['category'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218435"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enough to keep, so we won't drop this column\n",
    "filtered['total_awards_received'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realized after looking at the filtered dataset that Upvote Ratio and Category had a lot of NaNs, mainly due to the database not collecting Upvote Ratio until after a certain date and not many users using the Tags in Reddit to categorize their posts. We decided to drop these columns from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.drop(['Upvote Ratio', 'category'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency + clarity\n",
    "filtered.rename(columns={'created_utc':'Time Created UTC', 'total_awards_received':'Num Awards', 'score': 'Score', 'selftext':'Post Body'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Time Created UTC</th>\n",
       "      <th>Num Awards</th>\n",
       "      <th>Score</th>\n",
       "      <th>Post Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>t2_52yit</td>\n",
       "      <td>A question about Netflix and Amazon come Wedne...</td>\n",
       "      <td>1356455353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>With part of Netflix going down last night and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>t2_46mmt</td>\n",
       "      <td>Rosen Law Firm Announces Filing of Securities ...</td>\n",
       "      <td>1356378910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>t2_4mwkh</td>\n",
       "      <td>ZGNX insiders are expanding their position. Le...</td>\n",
       "      <td>1356330888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>t2_9b4e5</td>\n",
       "      <td>KeeneOnTheMarket.com -  Short the Russian Drou...</td>\n",
       "      <td>1356222842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>t2_9b4e5</td>\n",
       "      <td>KeeneOnTheMarket.com - Pregame Earnings: Optio...</td>\n",
       "      <td>1356043510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Author ID                                         Post Title  \\\n",
       "0           0  t2_52yit  A question about Netflix and Amazon come Wedne...   \n",
       "1           1  t2_46mmt  Rosen Law Firm Announces Filing of Securities ...   \n",
       "2           2  t2_4mwkh  ZGNX insiders are expanding their position. Le...   \n",
       "3           3  t2_9b4e5  KeeneOnTheMarket.com -  Short the Russian Drou...   \n",
       "4           4  t2_9b4e5  KeeneOnTheMarket.com - Pregame Earnings: Optio...   \n",
       "\n",
       "   Time Created UTC  Num Awards  Score  \\\n",
       "0        1356455353         NaN      0   \n",
       "1        1356378910         NaN      7   \n",
       "2        1356330888         NaN      0   \n",
       "3        1356222842         NaN      1   \n",
       "4        1356043510         NaN      1   \n",
       "\n",
       "                                           Post Body  \n",
       "0  With part of Netflix going down last night and...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Time Created UTC</th>\n",
       "      <th>Num Awards</th>\n",
       "      <th>Score</th>\n",
       "      <th>Post Body</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earnings season is here.  Place your bets.</td>\n",
       "      <td>1334162440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>I know that /r/investing is a great place for ...</td>\n",
       "      <td>2012-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earnings season is here.  Place your bets.</td>\n",
       "      <td>1334162440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>I know that /r/investing is a great place for ...</td>\n",
       "      <td>2012-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOG - beat estimates, price barely rises.</td>\n",
       "      <td>1334263051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOG - beat estimates, price barely rises.</td>\n",
       "      <td>1334263051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My poorly timed opening position for AAPL earn...</td>\n",
       "      <td>1334615377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>So I missed out on GOOG, which is probably a g...</td>\n",
       "      <td>2012-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317195</th>\n",
       "      <td>Complete DD on HYLN. No battery patent, no IP,...</td>\n",
       "      <td>1613142121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyliion became a thing in the WSB world once a...</td>\n",
       "      <td>2021-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317196</th>\n",
       "      <td>🚀</td>\n",
       "      <td>1613142124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2021-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317197</th>\n",
       "      <td>Buying tilray and nokia</td>\n",
       "      <td>1613142128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2021-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317198</th>\n",
       "      <td>Please take sndl at $3 !!</td>\n",
       "      <td>1613142129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2021-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317199</th>\n",
       "      <td>MVIS going way up!!</td>\n",
       "      <td>1613142130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-02-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1317200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Post Title  Time Created UTC  \\\n",
       "0               Earnings season is here.  Place your bets.        1334162440   \n",
       "1               Earnings season is here.  Place your bets.        1334162440   \n",
       "2               GOOG - beat estimates, price barely rises.        1334263051   \n",
       "3               GOOG - beat estimates, price barely rises.        1334263051   \n",
       "4        My poorly timed opening position for AAPL earn...        1334615377   \n",
       "...                                                    ...               ...   \n",
       "1317195  Complete DD on HYLN. No battery patent, no IP,...        1613142121   \n",
       "1317196                                                  🚀        1613142124   \n",
       "1317197                            Buying tilray and nokia        1613142128   \n",
       "1317198                          Please take sndl at $3 !!        1613142129   \n",
       "1317199                                MVIS going way up!!        1613142130   \n",
       "\n",
       "         Num Awards  Score                                          Post Body  \\\n",
       "0               NaN     13  I know that /r/investing is a great place for ...   \n",
       "1               NaN     13  I know that /r/investing is a great place for ...   \n",
       "2               NaN      2                                                NaN   \n",
       "3               NaN      2                                                NaN   \n",
       "4               NaN     12  So I missed out on GOOG, which is probably a g...   \n",
       "...             ...    ...                                                ...   \n",
       "1317195         0.0      1  Hyliion became a thing in the WSB world once a...   \n",
       "1317196         0.0      1                                          [removed]   \n",
       "1317197         0.0      1                                          [removed]   \n",
       "1317198         0.0      1                                          [removed]   \n",
       "1317199         0.0      1                                                NaN   \n",
       "\n",
       "               Date  \n",
       "0        2012-04-11  \n",
       "1        2012-04-11  \n",
       "2        2012-04-12  \n",
       "3        2012-04-12  \n",
       "4        2012-04-16  \n",
       "...             ...  \n",
       "1317195  2021-02-12  \n",
       "1317196  2021-02-12  \n",
       "1317197  2021-02-12  \n",
       "1317198  2021-02-12  \n",
       "1317199  2021-02-12  \n",
       "\n",
       "[1317200 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered['Date'] = pd.to_datetime(filtered['Time Created UTC'], unit='s').dt.date\n",
    "filtered = filtered.sort_values(by='Time Created UTC')\n",
    "filtered = filtered.reset_index(drop=True)\n",
    "filtered = filtered.drop(filtered.columns[[0]], axis=1)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include cells that describe the steps in your data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a potential bias in how we webscrape the Reddit API. This bias may come from how we build our dataset from Reddit, as just selecting certain threads might influence our dataset. Another bias could come from the culture of Reddit, in which some threads have certain patterns and trends in commenting and posting. However, we do not have biases coming from our group. We are not involved at all with Reddit, and therefore do not present a bias personally. However, if we gravitate to webscraping certain threads, then we may introduce a bias. We will try to detect these by going through reddit threads we are webscraping, and making sure all of them are not those that we are familiar with.\n",
    "\n",
    "Privacy is another problem. While Reddit data is public property, there are IDs and usernames involved. It is extremely easy to look up reddit usernames, posts, and comments to find the particular post on reddit. We are looking into deanonymizing the data by removing names, usernames, ids, posts, and titles. We are hoping to only publish our sentiment analysis rather than our dataset to prevent people from looking up posts and usernames. If not, this will be problematic as people can look up these posts and target specific users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your discussion information here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Specify who in your group worked on which parts of the project.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
