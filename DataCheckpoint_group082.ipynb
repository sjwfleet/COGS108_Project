{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Samuel\n",
    "- Matthew\n",
    "- Caitlin\n",
    "- Darren\n",
    "- Nick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do large online communities ( of retail traders) have influence over the stock market?\n",
    "\n",
    "*Sentiment analysis of positivity on the Reddit subreddit r/WallStreetBets and how this correlates to the performance of the S&P 500 from January 31, 2012 to the present.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Dataset\n",
    "\n",
    "- Dataset Name: Stock Market S&P 500 History \n",
    "- Link to the dataset: https://finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC\n",
    "- Number of observations: 2273\n",
    "\n",
    "This dataset contains the date, open, high, low, close, adjusted close, and volume of the S&P 500 from January 31, 2012 to February 10, 2021. We got this dataset from Yahoo Finance, which allows us to easily download the history of the S&P 500 into a CSV file. We chose this time period as the subreddit r/wallstreetbets was created on January 31, 2012. In our data cleaning code, we will only keep the date and closing columns.\n",
    "\n",
    "\n",
    "\n",
    "#### Reddit Dataset\n",
    "\n",
    "- Dataset Name: r/wallstreetbets submissions \n",
    "- Link to the dataset: https://www.kaggle.com/shergreen/wallstreetbets-subreddit-submissions?select=wallstreetbets_submission.json\n",
    "- Number of observations: 454025\n",
    "\n",
    "Our team found a dataset on Kaggle that gave us the submissions on r/wallstreetbets in a dataset that went up to August 2020. To ensure we covered the entire period within the scope of our question we elected to acquire our own data using wrappers for the Reddit API.\n",
    "\n",
    "If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets.\n",
    "\n",
    "\n",
    "\n",
    "*All of our datasets are included in the GitHub folder*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what we need for dataset paragraph:\n",
    "\n",
    "\n",
    "DATASET(S): What data will you use to answer your question? Describe the \n",
    "dataset(s) in terms of number of observations, what kind of features it \n",
    "contains, etc. (Typically students have datasets of ~1000 observations \n",
    "across their datasets. This is not a requirement, but is good to know around \n",
    "the scale of data we're expecting.) You are welcome (and in fact recommended) \n",
    "to find multiple datasets! If you do so, describe each one, and briefly \n",
    "explain how you will combine them together. Include the source of the dataset \n",
    "in the description here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Market S&P 500 History \n",
    "\n",
    "Our question is associated with how the positivity of the subreddit r/wallstreetbets correlates to the performance of the S&P 500 from January 31, 2012 to the present. This dataset before cleaning is already very clean. We just need to remove certain columns in order to get what we need to answer our research question. Therefore, we will just need the date and the closing price of the S&P 500. We do not need the adjusted close due to that we are working with the S&P 500 and don't need to work with out of hours like we would with an individual stock or the the opening price since it will just be the previous day's closing price. Since we are only considering the performance of the S&P 500, we do not need the volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we need for data cleaning paragraph\n",
    "\n",
    "DATA CLEANING: Get each of your datasets into a usable (likely, tidy) format. \n",
    "Briefly explain what steps you had to take before you were able to use the \n",
    "datasets you chose to answer your question of interest.\n",
    "\n",
    "How 'clean' is the data?\n",
    "What did you have to do to get the data into a usable format? (If you did \n",
    "nothing, how did you determine there was nothing to do?)\n",
    "What pre-processing steps that were required for your methods (for example, \n",
    "checking data distributions and performing any transformations that may be \n",
    "required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/31/2012</td>\n",
       "      <td>1312.410034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/2012</td>\n",
       "      <td>1324.089966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/2/2012</td>\n",
       "      <td>1325.540039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/3/2012</td>\n",
       "      <td>1344.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/6/2012</td>\n",
       "      <td>1344.329956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>2/4/2021</td>\n",
       "      <td>3871.739990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>2/5/2021</td>\n",
       "      <td>3886.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>2/8/2021</td>\n",
       "      <td>3915.590088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>2/9/2021</td>\n",
       "      <td>3911.229980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>2/10/2021</td>\n",
       "      <td>3909.879883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2273 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Close\n",
       "0     1/31/2012  1312.410034\n",
       "1      2/1/2012  1324.089966\n",
       "2      2/2/2012  1325.540039\n",
       "3      2/3/2012  1344.900024\n",
       "4      2/6/2012  1344.329956\n",
       "...         ...          ...\n",
       "2268   2/4/2021  3871.739990\n",
       "2269   2/5/2021  3886.830078\n",
       "2270   2/8/2021  3915.590088\n",
       "2271   2/9/2021  3911.229980\n",
       "2272  2/10/2021  3909.879883\n",
       "\n",
       "[2273 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_csv(\"Stock_Market_S&P_500_History.csv\")\n",
    "cleaned_stocks = stocks[['Date', 'Close']]\n",
    "cleaned_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reddit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal (updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/11  | 9 PM  | Finalising our initial look at chosen databases | Finish creating checkpoint\n",
    "| 2/12  | Before 11:59 PM  | NA | Turn in Checkpoint #1: Data |\n",
    "| 2/15  | 8 PM  | Start data wrangling beyond initial setup | Start exploring EDA \n",
    "| 2/17  | 8 PM  | Finalize wrangling/EDA; Begin Analysis /// | Discuss/edit Analysis |\n",
    "| 2/22  | 8 PM  | Work on individual tasks | Review all work thus far, finish and submit checkpoint 2   |\n",
    "| 2/26  | Before 11:59 PM  | NA | Turn in Checkpoint #2: EDA  |\n",
    "| 3/3  | 8 PM  | Start to look at final project deliverable | Begin finishing analysis |\n",
    "| 3/8  | 8 PM  | Complete analysis; Draft results/conclusion/discussion /// | Work on and discuss the final deliverable |\n",
    "| 3/19 [??]  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
