{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project (change this to your project's title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [X] YES - make available\n",
    "* [  ] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your overview here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Samuel\n",
    "- Matthew\n",
    "- Caitlin\n",
    "- Darren\n",
    "- Nick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do large online communities ( of retail traders) have influence over the stock market?\n",
    "\n",
    "*Sentiment analysis of positivity on the Reddit subreddit r/WallStreetBets and how this correlates to the performance of the S&P 500 from January 31, 2012 to the present.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='background'></a>\n",
    "\n",
    "## Background & Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reddit was considered a good community for us to hone in on for our topic not just because of its size, but also because it has a dedicated system for us to more easily scrape semi-structured data from the site. We are able to do this with the Python Reddit API Wrapper (PRAW). For the past few days the subreddit r/WallStreetBets has been the center of the trading world with its short squeeze of the Gamestock (GME), AMC Theaters (AMC), and BlackBerry (BB) stocks and more. Their history of trading in a reckless manner goes back much further than just the past few weeks. In this project we look at the trading done in the months leading up to and during the Covid-19 pandemic and how it correlates to several stocks including the S&P 500, TSLA, GME, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keith Gill, also know as the Roaring Kitty on Reddit, Tik Tok, and Youtube, invested $53,000 into GameStop (3). Recently he and his followers invested into GameStop against hedge funds and went against Wall Street norms. He and his fellow investors drove up the price of GameStop, which is still climbing to this day (4). Because Gill's base was mainly on Reddit, we were curious if there was any correlation with the positivity of the subreddit he frequented and the S&P 500. We did some research to see if scraping data from reddit was possible, and according to (2), it would be quite simple to create our own dataset using Reddit's API. We also looked into Kaggle, to see what our ideal dataset would look like (1). Using these resources, we feel confident in our ability to webscrape our own Reddit dataset. We also looked into downloading a dataset from websites that have the history and time periods of stocks. Yahoo Finance provides an easy way to download a dataset with the variables we need in .csv format (4).\n",
    "\n",
    "\n",
    "References (include links):\n",
    "- 1) https://www.kaggle.com/shergreen/wallstreetbets-subreddit-submissions\n",
    "- 2) https://towardsdatascience.com/scraping-reddit-data-1c0af3040768\n",
    "- 3) https://www.nytimes.com/2021/01/29/technology/roaring-kitty-reddit-gamestop-markets.html\n",
    "- 4) https://finance.yahoo.com/quote/GME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that there is a correlation between the positivity on the subreddit and the performance of the S&P 500 due to global and local events. Global events, especially the COVID-19 pandemic, may hold an influence over the subreddit and the market.\n",
    "- We also hypothesize that there will be a positive linear relationship between the performance of the S&P 500 and positivity on the popular subredditr r/WallStreetBets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Dataset\n",
    "\n",
    "- Dataset Name: Stock Market S&P 500 History \n",
    "- Link to the dataset: https://finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC\n",
    "- Number of observations: 2,273\n",
    "\n",
    "This dataset contains the date, open, high, low, close, adjusted close, and volume of the S&P 500 from January 31, 2012 to February 10, 2021. We got this dataset from Yahoo Finance, which allows us to easily download the history of the S&P 500 into a CSV file. We chose this time period as the subreddit r/wallstreetbets was created on January 31, 2012. In our data cleaning code, we will only keep the date and closing columns.\n",
    "\n",
    "\n",
    "\n",
    "#### Reddit Dataset\n",
    "\n",
    "- Dataset Name: Wallstreetbets Subs Full\n",
    "- Link to the dataset: https://drive.google.com/file/d/1l3NuVbJtf9mdMdvLsKRnj0rcfYYp7o28/view?usp=sharing\n",
    "- Number of observations: 1,317,200\n",
    "\n",
    "Our team found a dataset on Kaggle that gave us the submissions on r/wallstreetbets in a dataset that went up to August 2020. To ensure we covered the entire period within the scope of our question we elected to acquire our own data using wrappers for the Reddit API. We have included our webscraping code below. We webscraped the Reddit API from January 31, 2012 (when the subreddit was created) to the present. This dataset contains submissions to the subreddit. Other columns include features in Reddit (awards, removals, etc.) as well as links to posts and authors. We will be cleaning this up to better organize the data by date and post content.\n",
    "\n",
    "*Our stock dataset is included in the GitHub folder.*\n",
    "\n",
    "*Our reddit dataset is provided in a Google Drive link as the file is 1.7 gb.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your data cleaning steps here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include cells that describe the steps in your data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a potential bias in how we webscrape the Reddit API. This bias may come from how we build our dataset from Reddit, as just selecting certain threads might influence our dataset. Another bias could come from the culture of Reddit, in which some threads have certain patterns and trends in commenting and posting. However, we do not have biases coming from our group. We are not involved at all with Reddit, and therefore do not present a bias personally. However, if we gravitate to webscraping certain threads, then we may introduce a bias. We will try to detect these by going through reddit threads we are webscraping, and making sure all of them are not those that we are familiar with.\n",
    "\n",
    "Privacy is another problem. While Reddit data is public property, there are IDs and usernames involved. It is extremely easy to look up reddit usernames, posts, and comments to find the particular post on reddit. We are looking into deanonymizing the data by removing names, usernames, ids, posts, and titles. We are hoping to only publish our sentiment analysis rather than our dataset to prevent people from looking up posts and usernames. If not, this will be problematic as people can look up these posts and target specific users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your discussion information here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Specify who in your group worked on which parts of the project.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
